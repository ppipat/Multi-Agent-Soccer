{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "### Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"python/\")\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from dqn.dqn_agent_v2 import Agent\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Soccer.app\"`\n",
    "- **Windows** (x86): `\"path/to/Soccer_Windows_x86/Soccer.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Soccer_Windows_x86_64/Soccer.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Soccer_Linux/Soccer.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Soccer_Linux/Soccer.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Soccer_Linux_NoVis/Soccer.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Soccer_Linux_NoVis/Soccer.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Soccer.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Soccer.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 2\n",
      "        Number of External Brains : 2\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: GoalieBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 112\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "Unity brain name: StrikerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 112\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 6\n",
      "        Vector Action descriptions: , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Soccer_Env/Soccer.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we obtain separate brains for the striker and goalie agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GoalieBrain', 'StrikerBrain']\n"
     ]
    }
   ],
   "source": [
    "# print the brain names\n",
    "print(env.brain_names)\n",
    "\n",
    "# set the goalie brain\n",
    "g_brain_name = env.brain_names[0]\n",
    "g_brain = env.brains[g_brain_name]\n",
    "\n",
    "# set the striker brain\n",
    "s_brain_name = env.brain_names[1]\n",
    "s_brain = env.brains[s_brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of goalie agents: 2\n",
      "Number of striker agents: 2\n",
      "Number of goalie actions: 4\n",
      "Number of striker actions: 6\n",
      "There are 2 goalie agents. Each receives a state with length: 336\n",
      "There are 2 striker agents. Each receives a state with length: 336\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)\n",
    "\n",
    "# number of agents \n",
    "num_g_agents = len(env_info[g_brain_name].agents)\n",
    "print('Number of goalie agents:', num_g_agents)\n",
    "num_s_agents = len(env_info[s_brain_name].agents)\n",
    "print('Number of striker agents:', num_s_agents)\n",
    "\n",
    "# number of actions\n",
    "g_action_size = g_brain.vector_action_space_size\n",
    "print('Number of goalie actions:', g_action_size)\n",
    "s_action_size = s_brain.vector_action_space_size\n",
    "print('Number of striker actions:', s_action_size)\n",
    "\n",
    "# examine the state space \n",
    "g_states = env_info[g_brain_name].vector_observations\n",
    "g_state_size = g_states.shape[1]\n",
    "print('There are {} goalie agents. Each receives a state with length: {}'.format(g_states.shape[0], g_state_size))\n",
    "s_states = env_info[s_brain_name].vector_observations\n",
    "s_state_size = s_states.shape[1]\n",
    "print('There are {} striker agents. Each receives a state with length: {}'.format(s_states.shape[0], s_state_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Agent\n",
    "\n",
    "Attempt to implement DQN, leveraging Udacity Deep Reinforcement Learning [repo](https://github.com/udacity/deep-reinforcement-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_agent = Agent(state_size=g_state_size, action_size=g_action_size, seed=0)\n",
    "s_agent = Agent(state_size=s_state_size, action_size=s_action_size, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to modify reward structure to incentivize going after the ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ball_reward(state):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "        state : current state of striker, 3 stacked 112 element vector\n",
    "            1: ball\n",
    "            2: opponent's goal\n",
    "            3: own goal\n",
    "            4: wall\n",
    "            5: teammate\n",
    "            6: opponent\n",
    "            7: distance\n",
    "    \"\"\"\n",
    "    reward = 0.0\n",
    "    # Penalize if ball is not in view\n",
    "    if not any(state[0::8]):\n",
    "        reward = -0.03\n",
    "    # Reward for kicking the ball\n",
    "    else:\n",
    "        idx = np.where(state[0::8])[0] # check which ray sees the ball\n",
    "        distance = state[idx*8 + 7] # get the corresponding distance to ball\n",
    "        if (np.amin(distance) <= 0.03): # Just picking some thresholds for now.\n",
    "            reward = 0.3\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    g_losses = []\n",
    "    g_losses_window = deque(maxlen=100)\n",
    "    s_losses = []\n",
    "    s_losses_window = deque(maxlen=100)\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info  = env.reset(train_mode=True)\n",
    "        score = 0\n",
    "        ball_reward_val = 0.0\n",
    "        \n",
    "        g_states = env_info[g_brain_name].vector_observations       # get initial state (goalies)\n",
    "        s_states = env_info[s_brain_name].vector_observations       # get initial state (strikers)\n",
    "\n",
    "        g_scores = np.zeros(num_g_agents)                           # initialize the score (goalies)\n",
    "        s_scores = np.zeros(num_s_agents)                           # initialize the score (strikers)  \n",
    "        \n",
    "        for t in range(max_t):\n",
    "            action_g_0 = g_agent.act(g_states[0], eps)        # always pick state index 0\n",
    "            action_s_0 = s_agent.act(s_states[0], eps)  \n",
    "            \n",
    "            # Set other team to random\n",
    "            action_g_1 = np.asarray( [np.random.choice(g_action_size)] ) \n",
    "            action_s_1 = np.asarray( [np.random.choice(s_action_size)] )\n",
    "            # Train simultaneously\n",
    "            #action_g_1 = g_agent.act(g_states[1], eps)        # always pick state index 1\n",
    "            #action_s_1 = s_agent.act(s_states[1], eps) \n",
    "            \n",
    "            # Combine actions\n",
    "            actions_g = np.array( (action_g_0, action_g_1) )                                    \n",
    "            actions_s = np.array( (action_s_0, action_s_1) )\n",
    "            actions = dict( zip( [g_brain_name, s_brain_name], [actions_g, actions_s] ) )\n",
    "            \n",
    "            env_info = env.step(actions)                                                \n",
    "            # get next states\n",
    "            g_next_states = env_info[g_brain_name].vector_observations         \n",
    "            s_next_states = env_info[s_brain_name].vector_observations\n",
    "            \n",
    "            # get reward and update scores\n",
    "            g_rewards = env_info[g_brain_name].rewards\n",
    "            #print(g_rewards)\n",
    "            s_rewards = env_info[s_brain_name].rewards\n",
    "            #print(s_rewards)\n",
    "            g_scores += g_rewards\n",
    "            s_scores += s_rewards\n",
    "            \n",
    "            ball_reward_val += ball_reward(s_states[0])\n",
    "            \n",
    "            # check if episode finished\n",
    "            done = np.any(env_info[g_brain_name].local_done)\n",
    "            print(env_info[g_brain_name].text_observations)\n",
    "            print(env_info[g_brain_name].visual_observations)\n",
    "            \n",
    "            # store experiences\n",
    "            g_agent.step(g_states[0], action_g_0, g_rewards[0], \n",
    "                         g_next_states[0], done)\n",
    "            s_agent.step(s_states[0], action_s_0, s_rewards[0] + ball_reward(s_states[0]), # adding ball reward\n",
    "                         s_next_states[0], done)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "            g_states = g_next_states\n",
    "            s_states = s_next_states\n",
    "                \n",
    "        # learn\n",
    "        goalie_loss = g_agent.learn(g_agent.memory.sample(), 0.99) # discount = 0.99\n",
    "        striker_loss = s_agent.learn(s_agent.memory.sample(), 0.99) # discount = 0.99 \n",
    "        \n",
    "        g_losses.append(goalie_loss.item())\n",
    "        g_losses_window.append(goalie_loss.item())\n",
    "        s_losses.append(striker_loss.item())\n",
    "        s_losses_window.append(striker_loss.item())\n",
    "        \n",
    "        score = g_scores[0] + s_scores[0]\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        \n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\t Goalie Loss:' \\\n",
    "                  '{:.5f}\\t Striker Loss: {:.5f}' \\\n",
    "                  '\\t Ball Reward: {:.2f}'.format(i_episode, \\\n",
    "                                                  np.mean(scores_window), \\\n",
    "                                                  np.mean(g_losses_window), \\\n",
    "                                                  np.mean(s_losses_window), \\\n",
    "                                                  ball_reward_val), end=\"\")\n",
    "        #print(s_states[0][0:56])\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\t Goalie Loss:' \\\n",
    "                  '{:.5f}\\t Striker Loss: {:.5f}\\n' \\\n",
    "                  '\\t Ball Reward: {:.2f}'.format(i_episode, \\\n",
    "                                                  np.mean(scores_window), \\\n",
    "                                                  np.mean(g_losses_window), \\\n",
    "                                                  np.mean(s_losses_window), \\\n",
    "                                                  ball_reward_val))\n",
    "            torch.save(g_agent.qnetwork_local.state_dict(), 'checkpoint_goalie.pth')\n",
    "            torch.save(s_agent.qnetwork_local.state_dict(), 'checkpoint_striker.pth')\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters and train DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "Episode 1\tAverage Score: -1.10\t Goalie Loss:0.01446\t Striker Loss: 0.30464\t Ball Reward: -0.69['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "Episode 2\tAverage Score: -1.10\t Goalie Loss:0.01549\t Striker Loss: 0.27493\t Ball Reward: -2.55['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "Episode 3\tAverage Score: -0.37\t Goalie Loss:0.01046\t Striker Loss: 0.27641\t Ball Reward: 3.15['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "Episode 4\tAverage Score: -0.00\t Goalie Loss:0.00795\t Striker Loss: 0.27668\t Ball Reward: 3.30['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "['', '']\n",
      "[]\n",
      "Episode 5\tAverage Score: 0.22\t Goalie Loss:0.00963\t Striker Loss: 0.28527\t Ball Reward: 5.52"
     ]
    }
   ],
   "source": [
    "n_episodes = 5000\n",
    "n_episodes = 5\n",
    "max_t = 100000\n",
    "eps_start = 1.0\n",
    "eps_end = 0.1\n",
    "eps_decay = 0.9995\n",
    "\n",
    "# Pick up where we left off\n",
    "#GOALIE = './trained_models/goalie_dqn_run1.pth'\n",
    "#STRIKER = './trained_models/striker_dqn_run1.pth'\n",
    "#g_agent.qnetwork_local.load (GOALIE )\n",
    "#s_agent.qnetwork_local.load( STRIKER )\n",
    "GOALIE = './trained_models/goalie_dqn_ballreward2.pth'\n",
    "STRIKER = './trained_models/striker_dqn_ballreward2.pth'\n",
    "g_agent.qnetwork_local.load (GOALIE )\n",
    "s_agent.qnetwork_local.load( STRIKER )\n",
    "\n",
    "# Train\n",
    "eps_start = 0.1\n",
    "eps_end = 0.1\n",
    "scores = dqn(n_episodes, max_t, eps_start, eps_end, eps_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained agents and run\n",
    "g_agent_red = Agent(state_size=g_state_size, action_size=g_action_size, seed=0)\n",
    "s_agent_red = Agent(state_size=s_state_size, action_size=s_action_size, seed=0)\n",
    "g_agent_blue = Agent(state_size=g_state_size, action_size=g_action_size, seed=0)\n",
    "s_agent_blue = Agent(state_size=s_state_size, action_size=s_action_size, seed=0)\n",
    "\n",
    "# RED TEAM -------------------------------------\n",
    "# DQN_base\n",
    "GOALIE_red = './trained_models/goalie_dqn_run1.pth'\n",
    "STRIKER_red = './trained_models/striker_dqn_run1.pth'\n",
    "# DQN_1\n",
    "# GOALIE_red = './trained_models/goalie_dqn_ballreward2.pth'\n",
    "# STRIKER_red = './trained_models/striker_dqn_ballreward2.pth'\n",
    "\n",
    "g_agent_red.qnetwork_local.load (GOALIE_red )\n",
    "s_agent_red.qnetwork_local.load( STRIKER_red )\n",
    "\n",
    "# BLUE TEAM -------------------------------------\n",
    "# DQN_base\n",
    "# GOALIE_blue = './trained_models/goalie_dqn_run1.pth'\n",
    "# STRIKER_blue = './trained_models/striker_dqn_run1.pth'\n",
    "\n",
    "# g_agent_blue.qnetwork_local.load (GOALIE_blue )\n",
    "# s_agent_blue.qnetwork_local.load( STRIKER_blue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from episode 1: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 2: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 3: [-0.83966672  0.26033333] (goalies), [-0.26033333  0.83966672] (strikers)\n",
      "Scores from episode 4: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 5: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 6: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 7: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 8: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 9: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 10: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 11: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 12: [ 0.31033333 -0.78966672] (goalies), [ 0.78966672 -0.31033333] (strikers)\n",
      "Scores from episode 13: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 14: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 15: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 16: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 17: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 18: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 19: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 20: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 21: [-0.28633332  0.81366668] (goalies), [-0.81366668  0.28633332] (strikers)\n",
      "Scores from episode 22: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 23: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 24: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 25: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 26: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 27: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 28: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 29: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 30: [ 0.40366667 -0.69633333] (goalies), [ 0.69633333 -0.40366667] (strikers)\n",
      "Scores from episode 31: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 32: [-0.51466672  0.58533334] (goalies), [-0.58533334  0.51466672] (strikers)\n",
      "Scores from episode 33: [ 0.447      -0.65300005] (goalies), [ 0.65300005 -0.447     ] (strikers)\n",
      "Scores from episode 34: [ 1.07200002 -0.0280001 ] (goalies), [ 0.0280001  -1.07200002] (strikers)\n",
      "Scores from episode 35: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 36: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 37: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 38: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 39: [ 0.36366667 -0.73633339] (goalies), [ 0.73633339 -0.36366667] (strikers)\n",
      "Scores from episode 40: [ 1.09033336 -0.00966664] (goalies), [ 0.00966664 -1.09033336] (strikers)\n",
      "Scores from episode 41: [ 0.79033334 -0.30966677] (goalies), [ 0.30966677 -0.79033334] (strikers)\n",
      "Scores from episode 42: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 43: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 44: [ 0.90533335 -0.19466677] (goalies), [ 0.19466677 -0.90533335] (strikers)\n",
      "Scores from episode 45: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 46: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 47: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 48: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 49: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 50: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 51: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 52: [-0.26466665  0.83533335] (goalies), [-0.83533335  0.26466665] (strikers)\n",
      "Scores from episode 53: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 54: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 55: [-0.76133339  0.33866667] (goalies), [-0.33866667  0.76133339] (strikers)\n",
      "Scores from episode 56: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 57: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 58: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 59: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 60: [-0.85966678  0.24033333] (goalies), [-0.24033333  0.85966678] (strikers)\n",
      "Scores from episode 61: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 62: [-0.22300004  0.87700002] (goalies), [-0.87700002  0.22300004] (strikers)\n",
      "Scores from episode 63: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 64: [ 0.72700002 -0.37299999] (goalies), [ 0.37299999 -0.72700002] (strikers)\n",
      "Scores from episode 65: [ 0.44533333 -0.65466672] (goalies), [ 0.65466672 -0.44533333] (strikers)\n",
      "Scores from episode 66: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 67: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 68: [-0.14466665  0.95533335] (goalies), [-0.95533335  0.14466665] (strikers)\n",
      "Scores from episode 69: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 70: [ 0.81200002 -0.28799998] (goalies), [ 0.28799998 -0.81200002] (strikers)\n",
      "Scores from episode 71: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 72: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 73: [-0.03800004  1.06200002] (goalies), [-1.06200002  0.03800004] (strikers)\n",
      "Scores from episode 74: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 75: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 76: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 77: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 78: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 79: [-0.24300004  0.85700002] (goalies), [-0.85700002  0.24300004] (strikers)\n",
      "Scores from episode 80: [ 0.80533335 -0.29466665] (goalies), [ 0.29466665 -0.80533335] (strikers)\n",
      "Scores from episode 81: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 82: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 83: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 84: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 85: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from episode 86: [-0.12466671  0.97533335] (goalies), [-0.97533335  0.12466671] (strikers)\n",
      "Scores from episode 87: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 88: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 89: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 90: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 91: [ 0.42366667 -0.67633333] (goalies), [ 0.67633333 -0.42366667] (strikers)\n",
      "Scores from episode 92: [-0.73966678  0.36033333] (goalies), [-0.36033333  0.73966678] (strikers)\n",
      "Scores from episode 93: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 94: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 95: [ 0.80866668 -0.29133338] (goalies), [ 0.29133338 -0.80866668] (strikers)\n",
      "Scores from episode 96: [-0.16133331  0.93866669] (goalies), [-0.93866669  0.16133331] (strikers)\n",
      "Scores from episode 97: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 98: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 99: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 100: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 101: [ 0.94200001 -0.15800004] (goalies), [ 0.15800004 -0.94200001] (strikers)\n",
      "Scores from episode 102: [ 0.18533334 -0.91466667] (goalies), [ 0.91466667 -0.18533334] (strikers)\n",
      "Scores from episode 103: [-0.37633338  0.72366667] (goalies), [-0.72366667  0.37633338] (strikers)\n",
      "Scores from episode 104: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 105: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 106: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 107: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 108: [-0.84966666  0.25033334] (goalies), [-0.25033334  0.84966666] (strikers)\n",
      "Scores from episode 109: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 110: [-0.67800005  0.422     ] (goalies), [-0.422       0.67800005] (strikers)\n",
      "Scores from episode 111: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 112: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 113: [-0.31799999  0.78200002] (goalies), [-0.78200002  0.31799999] (strikers)\n",
      "Scores from episode 114: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 115: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 116: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 117: [-0.48633332  0.61366668] (goalies), [-0.61366668  0.48633332] (strikers)\n",
      "Scores from episode 118: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 119: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 120: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 121: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 122: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 123: [-0.49466666  0.60533335] (goalies), [-0.60533335  0.49466666] (strikers)\n",
      "Scores from episode 124: [-0.35466677  0.74533334] (goalies), [-0.74533334  0.35466677] (strikers)\n",
      "Scores from episode 125: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 126: [-0.34466671  0.75533334] (goalies), [-0.75533334  0.34466671] (strikers)\n",
      "Scores from episode 127: [-0.37800005  0.72200001] (goalies), [-0.72200001  0.37800005] (strikers)\n",
      "Scores from episode 128: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 129: [-0.00799998  1.09200002] (goalies), [-1.09200002  0.00799998] (strikers)\n",
      "Scores from episode 130: [ 1.04700002 -0.05300004] (goalies), [ 0.05300004 -1.04700002] (strikers)\n",
      "Scores from episode 131: [-0.10966665  0.99033335] (goalies), [-0.99033335  0.10966665] (strikers)\n",
      "Scores from episode 132: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 133: [-0.53466672  0.56533334] (goalies), [-0.56533334  0.53466672] (strikers)\n",
      "Scores from episode 134: [ 1.02866669 -0.07133331] (goalies), [ 0.07133331 -1.02866669] (strikers)\n",
      "Scores from episode 135: [-0.10133331  0.99866669] (goalies), [-0.99866669  0.10133331] (strikers)\n",
      "Scores from episode 136: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 137: [-0.36300005  0.73700002] (goalies), [-0.73700002  0.36300005] (strikers)\n",
      "Scores from episode 138: [-0.95633333  0.14366667] (goalies), [-0.14366667  0.95633333] (strikers)\n",
      "Scores from episode 139: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 140: [ 0.39033334 -0.70966666] (goalies), [ 0.70966666 -0.39033334] (strikers)\n",
      "Scores from episode 141: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 142: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n",
      "Scores from episode 143: [1.00200002 1.00200002] (goalies), [-1.00200002 -1.00200002] (strikers)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'GoalieBrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-cb504895b1c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mg_brain_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_brain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mactions_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_s\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# get next states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CS 230\\Project\\Multi-Agent-Soccer\\python\\unityagents\\environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_global_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_b\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_external_brain_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_agents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GoalieBrain'"
     ]
    }
   ],
   "source": [
    "team_red_window_score = []\n",
    "team_red_window_score_wins = []\n",
    "\n",
    "team_blue_window_score = []\n",
    "team_blue_window_score_wins = []\n",
    "\n",
    "draws = []\n",
    "\n",
    "for i in range(500):                                       # play game for 2 episodes\n",
    "    env_info = env.reset(train_mode=True)                  # reset the environment    \n",
    "    g_states = env_info[g_brain_name].vector_observations  # get initial state (goalies)\n",
    "    s_states = env_info[s_brain_name].vector_observations  # get initial state (strikers)\n",
    "    g_scores = np.zeros(num_g_agents)                      # initialize the score (goalies)\n",
    "    s_scores = np.zeros(num_s_agents)                      # initialize the score (strikers)\n",
    "    while True:\n",
    "        # RED TEAM actions\n",
    "        action_g_0 = g_agent_red.act(g_states[0], 0)       # always pick state index 0 for red\n",
    "        action_s_0 = s_agent_red.act(s_states[0], 0)  \n",
    "\n",
    "        # BLUE TEAM actions\n",
    "        # ----- RANDOM -----\n",
    "        action_g_1 = np.asarray( [np.random.choice(g_action_size)] ) \n",
    "        action_s_1 = np.asarray( [np.random.choice(s_action_size)] )\n",
    "        # ----- Trained -----\n",
    "#         action_g_1 = g_agent_blue.act(g_states[1], 0)      # always pick state index 1 for blue\n",
    "#         action_s_1 = s_agent_blue.act(s_states[1], 0)\n",
    "\n",
    "        # Combine actions\n",
    "        actions_g = np.array( (action_g_0, action_g_1) )                                    \n",
    "        actions_s = np.array( (action_s_0, action_s_1) )\n",
    "        actions = dict( zip( [g_brain_name, s_brain_name], [actions_g, actions_s] ) )\n",
    "\n",
    "        env_info = env.step(actions)                       \n",
    "        \n",
    "        # get next states\n",
    "        g_next_states = env_info[g_brain_name].vector_observations         \n",
    "        s_next_states = env_info[s_brain_name].vector_observations\n",
    "        \n",
    "        # get reward and update scores\n",
    "        g_rewards = env_info[g_brain_name].rewards  \n",
    "        s_rewards = env_info[s_brain_name].rewards\n",
    "        g_scores += g_rewards\n",
    "        s_scores += s_rewards\n",
    "        \n",
    "        # check if episode finished\n",
    "        done = np.any(env_info[g_brain_name].local_done)  \n",
    "        \n",
    "        # roll over states to next time step\n",
    "        g_states = g_next_states\n",
    "        s_states = s_next_states\n",
    "        \n",
    "        # exit loop if episode finished\n",
    "        if done:                                           \n",
    "            break\n",
    "    team_red_score = g_scores[0] + s_scores[0]\n",
    "    team_red_window_score.append( team_red_score )\n",
    "    team_red_window_score_wins.append( 1 if team_red_score > 0 else 0)        \n",
    "\n",
    "    team_blue_score = g_scores[1] + s_scores[1]\n",
    "    team_blue_window_score.append( team_blue_score )\n",
    "    team_blue_window_score_wins.append( 1 if team_blue_score > 0 else 0 )\n",
    "\n",
    "    draws.append( team_red_score == team_blue_score )\n",
    "    print('Scores from episode {}: {} (goalies), {} (strikers)'.format(i+1, g_scores, s_scores))\n",
    "\n",
    "print('Red Wins: \\t{} \\tScore: \\t{:.5f} \\tAvg: \\t{:.2f} \\tDraws: \\t{}'.format( \\\n",
    "                  np.count_nonzero(team_red_window_score_wins), team_red_score, \\\n",
    "                  np.sum(team_red_window_score), np.count_nonzero(draws) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patipan\\Anaconda3\\envs\\Soccer\\lib\\multiprocessing\\connection.py\", line 312, in _recv_bytes\n",
      "    nread, err = ov.GetOverlappedResult(True)\n",
      "BrokenPipeError: [WinError 109] The pipe has been ended\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patipan\\Anaconda3\\envs\\Soccer\\lib\\site-packages\\grpc\\_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"python\\unityagents\\rpc_communicator.py\", line 26, in Exchange\n",
      "    return self.child_conn.recv()\n",
      "  File \"C:\\Users\\Patipan\\Anaconda3\\envs\\Soccer\\lib\\multiprocessing\\connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"C:\\Users\\Patipan\\Anaconda3\\envs\\Soccer\\lib\\multiprocessing\\connection.py\", line 321, in _recv_bytes\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
